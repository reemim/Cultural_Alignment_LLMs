# Compilation of Papers on Cultural Alignment in LLMs

## Introduction
Welcome to our repository dedicated to the collection of research and papers on cultural alignment alignment in Language Models. This compilation serves as a vital resource in understanding and ensuring the development of models that respect and integrate diverse cultural norms and values.
([culturalalignment.ai](https://culturalalignment.ai/))

### Purpose
This repository aims to:
- Serve as a centralized resource for researchers, students, and LLM enthusiasts.
- Enhance understanding of how LLMs aligns with various human values and cultural contexts.
- Stimulate discussion and promote further research in this critical area of LLM development.

## Contents
- [Papers](#papers)
- [Conferences and Workshops](#conferences-and-workshops)
- [How to Contribute](#how-to-contribute)

## Papers
Here, you'll find a curated list of academic papers, articles, and publications that explore the intersections of AI, Language Models, and cultural value alignment.

### 2024
- (2-2024) [Investigating Cultural Alignment of Large Language Models](https://arxiv.org/abs/2402.13231)
- (2-2024) [CIDAR: Culturally Relevant Instruction Dataset For Arabic](https://arxiv.org/abs/2402.03177)
### 2023
- (11-2023) [CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models](https://arxiv.org/abs/2311.16421)
- (8-2023) [Group Preference Optimization: Few-Shot Alignment of Large Language Models](https://arxiv.org/abs/2310.11523)
- (8-2023) [Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions](https://arxiv.org/abs/2309.12342)
- (8-2023  [Unmasking Nationality Bias: A Study of Human Perception of Nationalities in AI-Generated Articles] (https://arxiv.org/abs/2308.04346)
- (5-2023) [Training Socially Aligned Language Models on Simulated Social Interactions](https://arxiv.org/abs/2305.16960)
- (5-2023) [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models](https://arxiv.org/abs/2305.14456)
- (4-2023) [Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models](https://arxiv.org/pdf/2304.03738.pdf)
- (4-2023) [In Conversation with Artificial Intelligence: Aligning Language Models with Human Values](https://link.springer.com/article/10.1007/s13347-023-00606-x)
- (3-2034) [Whose Opinions Do Language Models Reflect?](https://arxiv.org/pdf/2303.17548.pdf)
- (3-2023) [Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study](https://arxiv.org/abs/2303.17466)
- (3-2023) [Probing Pre-Trained Language Models for Cross-Cultural Differences in Values](https://arxiv.org/abs/2203.13722)
- (2-2023) [Nationality Bias in Text Generation](https://arxiv.org/abs/2302.02463)

### 2022
- [Cultural Incongruencies in Artificial Intelligence](https://arxiv.org/pdf/2211.13069.pdf)
- [The Myth of Culturally Agnostic AI Models](https://arxiv.org/ftp/arxiv/papers/2211/2211.15271.pdf)
- [French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English](https://aclanthology.org/2022.acl-long.583/)

### 2021
- [Gender bias, social bias, and representation in Bollywood and Hollywood](https://www.sciencedirect.com/science/article/pii/S266638992100283X)

### 2020
- [Artificial Intelligence, Values, and Alignment](https://link.springer.com/article/10.1007/s11023-020-09539-2)
- [UNQOVERing Stereotypical Biases via Underspecified Questions](https://arxiv.org/abs/2010.02428)

### 2019
- [Assessing Social and Intersectional Biases in Contextualized Word Representations](https://arxiv.org/abs/1911.01485)


## Conferences and Workshops
Find information on relevant conferences and workshops focusing on cultural alignment in AI:

- [Cultures in AI/AI in Culture - A NeurIPS 2022 Workshop](https://ai-cultures.github.io/) - December, NeurIPS 2022.
- [Socially Responsible Language Modelling Research](https://solar-neurips.github.io/) - December, NeurIPS 2023.
- [Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP)](https://aclanthology.org/volumes/2023.c3nlp-1/) - May, Association for Computational Linguistics 2023.

## How to Contribute
We welcome contributions! You can help by:
- **Adding New Resources**: Share new findings or resources.
- **Updating Existing Entries**: Ensure information is up-to-date and accurate.
- **Enhancing Organization**: Offer suggestions for a more user-friendly experience.

To contribute:
1. Fork the repository.
2. Make your changes.
3. Submit a pull request with a detailed description of your changes.

### Contact
Have questions or suggestions? Feel free to [contact us](mailto:reem.masoud.22@ucl.ac.uk).
